import math
from typing import Dict, Optional, Tuple

import numpy as np
import torch
import torch.nn as nn
from dgl import DGLGraph  # â† íƒ€ì…íŒíŠ¸ ì“°ë©´ ê¼­ í•„ìš”
from core.config import Settings, IDX_TO_DISEASE  # â† íƒ€ì…/ìƒìˆ˜ ë‘˜ ë‹¤ ì‚¬ìš©

from sklearn.metrics import (
    roc_auc_score, average_precision_score,
    precision_score, recall_score, f1_score, accuracy_score
)
from tqdm import tqdm

from .builder import create_model_and_predictor

# -----------------------------
# í•™ìŠµ/í‰ê°€ ë£¨í”„
# -----------------------------
def train_one_fold(g: DGLGraph, feats: torch.Tensor,
                   train_uv: Tuple[torch.Tensor, torch.Tensor], train_y: torch.Tensor,
                   test_uv: Tuple[torch.Tensor, torch.Tensor], test_y: torch.Tensor,
                   params: Dict, settings: Settings, g_hetero,
                   person_dim: int, disease_dim: int, # << ì¶”ê°€
                   progress_desc: Optional[str] = None,
                   eval_info: Optional[Dict] = None) -> Dict[str, Dict[str, float]]:
    device = settings.device
    g = g.to(device)
    feats = feats.to(device)

    # HGT ê´€ë ¨ ë¡œì§ ì œê±° (ì´ì œ ë¶ˆí•„ìš”)
    # in_dim ê³„ì‚° ë¡œì§ ì œê±° (ì´ì œ ë¶ˆí•„ìš”)
    
    train_u, train_v = train_uv[0].to(device), train_uv[1].to(device)
    test_u, test_v = test_uv[0].to(device), test_uv[1].to(device)
    train_y, test_y = train_y.to(device), test_y.to(device)

    # 2. ëª¨ë¸ ìƒì„± ë¶€ë¶„ ìˆ˜ì •
    model, predictor = create_model_and_predictor(params, settings,
                                                  person_in_dim=person_dim,
                                                  disease_in_dim=disease_dim,
                                                  g_hetero=g_hetero)
    
    model.to(device); predictor.to(device)
    
    opt = torch.optim.AdamW(list(model.parameters()) + list(predictor.parameters()), lr=params['lr'], weight_decay=params['weight_decay'])
    loss_fn = nn.BCEWithLogitsLoss()

    epoch_losses = []
    
    # ë¯¸ë¦¬ CPUë¡œ ì˜®ê²¨ë‘ì–´ ë°˜ë³µ ê³„ì‚° ë°©ì§€
    test_y_cpu = test_y.cpu().numpy()

    # ğŸ”¹ AUROC ê¸°ì¤€ best epoch ì¶”ì ìš© ë³€ìˆ˜
    best_test_auroc = -float("inf")
    best_test_epoch = -1          # ë‚˜ì¤‘ì— 1-basedë¡œ ì €ì¥
    best_test_scores = None       # best epochì—ì„œì˜ test logits

    epoch_iter = tqdm(range(params['max_epochs']), desc=f"Epoch | {progress_desc}", ncols=80, leave=False) if progress_desc else range(params['max_epochs'])

    for epoch in epoch_iter:
        # --- 1. í•™ìŠµ ---
        model.train(); predictor.train()

        if not params["using_moe"]:
            logits = model.forward_edges(g, feats, predictor, uv=(train_u, train_v)).squeeze(-1)
            loss = loss_fn(logits, train_y.float())
        else:
            logits, moe_loss = model.forward_edges(g, feats, predictor, uv=(train_u, train_v))
            logits = logits.squeeze(-1)
            loss = loss_fn(logits, train_y.float())
            loss += moe_loss * 0.01               # 3 losses ì‚¬ìš© ì‹œ ì´ ë¶€ë¶„ ì£¼ì„í•´ì•¼ í•¨.

        opt.zero_grad(); loss.backward(); opt.step()
        epoch_losses.append(loss.item())
        
        # --- 2. ë§¤ ì—í­ë§ˆë‹¤ í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ì¸¡ì • (ëª¨ë‹ˆí„°ë§ìš©) ---
        model.eval(); predictor.eval()
        with torch.no_grad():
            if not params["using_moe"]:
                test_logits = model.forward_edges(g, feats, predictor, uv=(test_u, test_v)).squeeze(-1)
            #test_scores = torch.sigmoid(test_logits).cpu().numpy()
            else:
                test_logits, moe_loss = model.forward_edges(g, feats, predictor, uv=(test_u, test_v))
                test_logits = test_logits.squeeze(-1)

            test_scores_epoch = test_logits.cpu().numpy()
            
        try:
            test_auroc = roc_auc_score(test_y_cpu, test_scores_epoch)
        except ValueError:
            test_auroc = 0.0

        # ë² ìŠ¤íŠ¸ aurocë¥¼ ë§Œë‚  ê²½ìš° ê°±ì‹ 
        if test_auroc >= best_test_auroc:   # ë™ì¼í•˜ë©´ ë‚˜ì¤‘ epochì„ bestë¡œ
            best_test_auroc = test_auroc
            best_test_epoch = epoch + 1     # ì‚¬ëŒì´ ë³´ê¸° ì¢‹ê²Œ 1-based
            best_test_scores = test_scores_epoch

        #     torch.save(
        #     {
        #         "model": model.state_dict(),
        #         "predictor": predictor.state_dict()
        #     },
        #     f"../saved_models/best_model{settings.seed}.pth"
        # )
        
        # --- 3. ì§„í–‰ë¥  í‘œì‹œì¤„ ì—…ë°ì´íŠ¸ ---
        if hasattr(epoch_iter, "set_postfix"):
            epoch_iter.set_postfix(loss=loss.item(), 
                                   test_auroc=test_auroc,
                                   best_auroc=best_test_auroc,
                                   best_epoch=best_test_epoch
                                   )

    if hasattr(epoch_iter, "close"): epoch_iter.close()

    assert best_test_scores is not None, "best_test_scoresê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. train loopë¥¼ í™•ì¸í•˜ì„¸ìš”."

    test_scores_for_eval = best_test_scores

    # --- ìµœì¢… í‰ê°€ëŠ” ìµœê³  auc ì„±ëŠ¥ ì—í­ ëª¨ë¸ë¡œ í•œ ë²ˆë§Œ ìˆ˜í–‰ ---
    model.eval(); predictor.eval()
    with torch.no_grad():
        # test_logits = model.forward_edges(g, feats, predictor, uv=(test_u, test_v)).squeeze(-1)
        # test_scores = test_logits.cpu().numpy()
        
        p = settings.pred_threshold
        eps = 1e-12
        p = min(max(p, eps), 1 - eps)
        logit_thr = math.log(p / (1 - p))
        
        if eval_info:
            final_test_metrics = evaluate_multimorbidity_metrics(
                test_y_cpu, 
                #test_scores,
                test_scores_for_eval,
                threshold=logit_thr,
                eval_info=eval_info,
                idx_to_disease_map=IDX_TO_DISEASE
            )
        else:
            final_test_metrics = evaluate_metrics_binary(
                test_y_cpu, 
                #test_scores,
                test_scores_for_eval,
                threshold=logit_thr,
                disease_ids=None
            )

        if not params["using_moe"]:
            train_logits = model.forward_edges(g, feats, predictor, uv=(train_u, train_v)).squeeze(-1)
        else:
            logits, moe_loss = model.forward_edges(g, feats, predictor, uv=(train_u, train_v))
            train_logits = logits.squeeze(-1)

        train_scores = train_logits.cpu().numpy()
        
        final_train_metrics = evaluate_metrics_binary(
            train_y.cpu().numpy(), train_scores,
            threshold=logit_thr,
            disease_ids=None
        )

    # ğŸ”¹ best epoch / best auroc ì •ë³´ë„ ê°™ì´ ë„£ê¸°
    #   -> run_cross_validationì—ì„œ foldë³„ë¡œ í‰ê· /í‘œì¤€í¸ì°¨ë¥¼ ë‚¼ ìˆ˜ ìˆìŒ
    final_test_metrics["best_epoch_by_auroc"] = float(best_test_epoch)
    final_test_metrics["best_auroc_during_train"] = float(best_test_auroc)   

    return {"train": final_train_metrics, "test": final_test_metrics, "loss_history": epoch_losses}


def evaluate_metrics_binary(
    y_true: np.ndarray,
    y_score: np.ndarray,                 # model logit or prob
    threshold: float = 0.5,
    disease_ids: Optional[np.ndarray] = None
) -> Dict[str, float]:
    #y_scoreëŠ” ë¡œì§“ì´ì–´ë„ ë˜ê³ , í™•ë¥ ì´ì–´ë„ ë¨(roc/auprcëŠ” scoreë§Œ í•„ìš”).
    # ì „ì²´ ìŠ¤ì¹¼ë¼ ì§€í‘œ
    # - AUROC/AUPRCëŠ” score ì‚¬ìš©(ë¡œì§“ OK)
    out = {}
    try:
        out["auroc"] = float(roc_auc_score(y_true, y_score))
    except Exception:
        out["auroc"] = float("nan")
    try:
        out["auprc"] = float(average_precision_score(y_true, y_score))
    except Exception:
        out["auprc"] = float("nan")

    y_pred = (y_score >= threshold).astype(int)
    out["precision"] = float(precision_score(y_true, y_pred, zero_division=0))
    out["recall"]    = float(recall_score   (y_true, y_pred, zero_division=0))
    out["f1"]        = float(f1_score       (y_true, y_pred, zero_division=0))
    out["accuracy"]  = float(accuracy_score (y_true, y_pred))

    # ì§ˆë³‘ë³„ ì§‘ê³„
    if disease_ids is not None:
        # micro: ëª¨ë“  ìƒ˜í”Œ í†µí•© â†’ ì´ë¯¸ ê³„ì‚°ëœ ê²ƒê³¼ ë™ì¼(precision/recall/f1/auprc/auroc)
        # macro: ì§ˆë³‘ë³„ë¡œ ì‚°ì¶œ í›„ í‰ê· 
        uniq = np.unique(disease_ids)
        per_cls_auroc, per_cls_auprc, per_cls_rec, per_cls_f1 = [], [], [], []
        for d in uniq:
            mask = (disease_ids == d)
            if mask.sum() == 0:
                continue
            y_t, y_s = y_true[mask], y_score[mask]
            y_p = (y_s >= threshold).astype(int)
            try:
                per_cls_auroc.append(roc_auc_score(y_t, y_s))
            except Exception:
                pass
            try:
                per_cls_auprc.append(average_precision_score(y_t, y_s))
            except Exception:
                pass
            per_cls_rec.append(recall_score(y_t, y_p, zero_division=0))
            per_cls_f1.append(f1_score(y_t, y_p, zero_division=0))

        if per_cls_auroc:
            out["macro_auroc"] = float(np.mean(per_cls_auroc))
        if per_cls_auprc:
            out["macro_auprc"] = float(np.mean(per_cls_auprc))
        if per_cls_rec:
            out["macro_recall"] = float(np.mean(per_cls_rec))
        if per_cls_f1:
            out["f1_macro"] = float(np.mean(per_cls_f1))

    return out

def evaluate_multimorbidity_metrics(
    y_true: np.ndarray,
    y_score: np.ndarray,
    threshold: float,
    eval_info: Dict,
    idx_to_disease_map: Dict[int, str]
) -> Dict[str, float]:
    # test_person_tids = eval_info['test_person_tids']
    # known_disease_map = eval_info['known_disease_map']
    
    # Macro ê³„ì‚°ì„ ìœ„í•´ ì§ˆë³‘ IDë¥¼ evaluate_metrics_binaryì— ì „ë‹¬
    test_disease_tids = eval_info.get('test_disease_tids') # eval_infoì—ì„œ ì§ˆë³‘ ID ê°€ì ¸ì˜¤ê¸°

    # 1. ì „ì²´ ì„±ëŠ¥ ê³„ì‚° (Microì™€ Macro ëª¨ë‘ í¬í•¨)
    results = evaluate_metrics_binary(y_true, y_score, threshold=threshold, disease_ids=test_disease_tids)

    # # 2. ê¸°ì €ì§ˆí™˜ë³„ ì„±ëŠ¥ ê³„ì‚° (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    # for disease_idx, disease_name in idx_to_disease_map.items():
    #     persons_with_base_disease = {
    #         p_id for p_id, diseases in known_disease_map.items() if disease_idx in diseases
    #     }

    #     if not persons_with_base_disease:
    #         continue

    #     mask = np.isin(test_person_tids, list(persons_with_base_disease))
        
    #     if np.sum(mask) < 2 or len(np.unique(y_true[mask])) < 2:
    #         continue

    #     y_true_subset, y_score_subset = y_true[mask], y_score[mask]

    #     try:
    #         results[f"auroc_given_{disease_name}"] = float(roc_auc_score(y_true_subset, y_score_subset))
    #     except ValueError:
    #         results[f"auroc_given_{disease_name}"] = float("nan")
        
    #     y_pred_subset = (y_score_subset >= threshold).astype(int)
    #     results[f"f1_given_{disease_name}"] = float(f1_score(y_true_subset, y_pred_subset, zero_division=0))
    #     results[f"recall_given_{disease_name}"] = float(recall_score(y_true_subset, y_pred_subset, zero_division=0))

    return results